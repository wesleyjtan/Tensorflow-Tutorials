{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Guide to TF Layers: Building a Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow layers module provides a high-level API that makes it easy to construct a neural network. It provides methods that facilitate the creation of dense (fully connected) layers and convolutional layers, adding activation functions, and applying dropout regularization. In this tutorial, you'll learn how to use layers to build a convolutional neural network model to recognize the handwritten digits in the MNIST data set.\n",
    "\n",
    "The MNIST dataset comprises 60,000 training examples and 10,000 test examples of the handwritten digits 0â€“9, formatted as 28x28-pixel monochrome images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the skeleton for our TensorFlow program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # input layer\n",
    "    \"\"\"for creating convolutional and pooling layers for two-dimensional image data expect input tensors to have a shape of [batch_size, image_width, image_height, channels]\"\"\"\n",
    "    \"\"\"indicated -1 for batch size, which specifies that this dimension should be dynamically computed based on the number of input values in features[\"x\"]\"\"\"\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])    \n",
    "    \n",
    "    #convolutional layer #1\n",
    "    # dimensions of the filters as [width, height] (here, [5, 5])\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[5, 5],\n",
    "                             padding=\"same\", activation=tf.nn.relu)\n",
    "    \"\"\"output tensor produced by conv2d() has a shape of [batch_size, 28, 28, 32]: the same width and height dimensions as the input, but now with 32 channels holding the output from each of the filters\"\"\"\n",
    "    \n",
    "    #pooling layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                                    strides=2)\n",
    "    \n",
    "    #convolutional layer #2 and pooling layer #2\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, \n",
    "                             kernel_size=[5, 5], padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                                    strides=2)\n",
    "    \n",
    "    #dense layer\n",
    "    \"\"\"Each example has 7 (pool2 width) * 7 (pool2 height) * 64 (pool2 channels) features, so we want the features dimension to have a value of 7 * 7 * 64 (3136 in total). The output tensor, pool2_flat, has shape [batch_size, 3136]\"\"\"\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4,\n",
    "                                training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    #logits layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)    \n",
    "    #logits layer of our model returns our predictions as raw values in a [batch_size, 10]-dimensional tensor.\n",
    "    \n",
    "    #generate predictions\n",
    "    predictions = {\n",
    "        #predicted class \n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        #derive probabilities from our logits layer by applying softmax activation\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    #compile our predictions in a dict, and return an EstimatorSpec object\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    #calculate Loss (for both TRAIN and EVAL modes)\n",
    "#     loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)    \n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    \"\"\"takes onehot_labels and logits as arguments, performs softmax activation on logits, calculates cross-entropy, and returns our loss as a scalar Tensor\"\"\"    \n",
    "    loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels=onehot_labels, logits=logits)\n",
    "\n",
    "    #configure the Training Op (for TRAIN mode)\n",
    "    #configure our model to optimize this loss value during training\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(\n",
    "                                    labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating the CNN MNIST Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load our training and test data. Add a main() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    #load training and eval data\n",
    "    mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "    train_data = mnist.train.images #returns np.array\n",
    "    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    eval_data = mnist.test.images #returns np.array\n",
    "    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "    \n",
    "    #create estimator(a TensorFlow class for performing high-level model training, evaluation, and inference)\n",
    "    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, \n",
    "                                             model_dir=\"/tmp/mnist_convnet_model\")\n",
    "    #set up logging for predictions so we can track progress during training \n",
    "    #log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "    #train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": train_data},\n",
    "                        y=train_labels, batch_size=100, num_epochs=None, shuffle=True)\n",
    "    mnist_classifier.train(input_fn=train_input_fn, steps=20000, hooks=[logging_hook]) \n",
    "    \n",
    "    #evaluate the model and print results\n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(x={\"x\": eval_data},\n",
    "                       y=eval_labels, num_epochs=1, shuffle=False)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envtf",
   "language": "python",
   "name": "envtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
